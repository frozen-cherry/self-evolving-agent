#!/usr/bin/env python3
"""
Moltbook å†…å®¹åˆ†æå’Œè¿è¥ç­–ç•¥å·¥å…·
åˆ†æçœŸå®å¹³å°å†…å®¹ï¼Œæä¾›å¯æ‰§è¡Œçš„è¿è¥å»ºè®®
"""

import requests
import json
import time
import re
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Any
import random
from pathlib import Path

def get_api_key():
    """è·å–Moltbook API Key"""
    import os
    api_key = os.environ.get('MOLTBOOK_API_KEY')
    if api_key:
        return api_key
    
    config_path = Path.home() / '.config' / 'moltbook' / 'credentials.json'
    if config_path.exists():
        try:
            with open(config_path) as f:
                config = json.load(f)
                return config.get('api_key', '')
        except:
            pass
    return ''

def parse_feed_output(feed_output: str) -> List[Dict]:
    """è§£æ moltbook_feed çš„è¾“å‡ºæ ¼å¼ä¸ºå­—å…¸åˆ—è¡¨"""
    posts = []
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ¯ä¸ªå¸–å­
    pattern = r'(\d+)\.\s*ğŸ“\s*(?:æ–‡å­—|é“¾æ¥)\s*\*\*(.*?)\*\*\s*â¤ï¸\s*(\d+)\s*\|\s*ğŸ’¬\s*(\d+)\s*ğŸ“‹\s*(.*?)\s*ğŸ“\s*(.*?)\s*ğŸ†”\s*ID:\s*(.*?)(?=\n|$)'
    matches = re.findall(pattern, feed_output, re.DOTALL)
    
    for match in matches:
        try:
            rank, author_name, likes, comments, title, content, post_id = match
            
            post = {
                'id': post_id.strip(),
                'author': {'name': author_name.strip()},
                'likes': int(likes),
                'comments': int(comments),
                'title': title.strip(),
                'content': content.strip(),
                'url': '',
                'type': 'text'
            }
            posts.append(post)
        except (ValueError, IndexError) as e:
            print(f"è§£æå¸–å­å¤±è´¥: {e}")
            continue
    
    return posts

class MoltbookAnalyzer:
    def __init__(self):
        self.base_url = "https://www.moltbook.com/api/v1"
        self.api_key = get_api_key()
        self.headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
    def get_latest_feed(self, limit: int = 50) -> List[Dict]:
        """ä»çœŸå®APIè·å–feedå†…å®¹"""
        try:
            response = requests.get(
                f"{self.base_url}/posts",
                headers=self.headers,
                params={'sort': 'hot', 'limit': limit},
                timeout=15
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                print(f"APIé”™è¯¯: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"è·å–feedå¤±è´¥: {e}")
            return []
    
    def analyze_hot_content(self, posts: List[Dict]) -> Dict[str, Any]:
        """åˆ†æçƒ­é—¨å†…å®¹"""
        if not posts:
            return {"top_posts": [], "rising_posts": [], "trending_topics": []}
        
        hot_posts = sorted(posts, key=lambda x: x.get('likes', 0), reverse=True)[:5]
        
        rising_posts = []
        for post in posts:
            likes = post.get('likes', 0)
            comments = post.get('comments', 0)
            if likes > 0 and comments > 0:
                engagement_rate = comments / likes
                if engagement_rate > 0.1:
                    rising_posts.append({
                        'post': post,
                        'engagement_rate': engagement_rate,
                        'score': likes * 0.7 + comments * 0.3
                    })
        
        rising_posts.sort(key=lambda x: x['score'], reverse=True)
        rising_posts = [item['post'] for item in rising_posts[:3]]
        
        trending_topics = self._extract_trending_topics(posts)
        
        return {
            "top_posts": hot_posts,
            "rising_posts": rising_posts,
            "trending_topics": trending_topics
        }
    
    def analyze_authors(self, posts: List[Dict]) -> Dict[str, Any]:
        """åˆ†æä½œè€…è´¨é‡"""
        author_stats = {}
        
        for post in posts:
            author = post.get('author', {})
            author_name = author.get('name', 'unknown')
            
            if author_name not in author_stats:
                author_stats[author_name] = {
                    'author': author,
                    'posts_count': 0,
                    'total_likes': 0,
                    'total_comments': 0,
                    'avg_engagement': 0,
                    'quality_score': 0
                }
            
            stats = author_stats[author_name]
            stats['posts_count'] += 1
            stats['total_likes'] += post.get('likes', 0)
            stats['total_comments'] += post.get('comments', 0)
        
        for stats in author_stats.values():
            if stats['posts_count'] > 0:
                stats['avg_engagement'] = (stats['total_likes'] + stats['total_comments']) / stats['posts_count']
                stats['quality_score'] = stats['avg_engagement'] * stats['posts_count']
        
        top_authors = sorted(author_stats.values(), key=lambda x: x['quality_score'], reverse=True)[:5]
        
        return {
            "top_authors": top_authors,
            "active_authors_count": len(author_stats),
            "avg_posts_per_author": sum(s['posts_count'] for s in author_stats.values()) / len(author_stats) if author_stats else 0
        }
    
    def generate_engagement_suggestions(self, posts: List[Dict], analysis: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆå¯æ‰§è¡Œçš„äº’åŠ¨å»ºè®®"""
        suggestions = {
            "like_targets": [],
            "follow_targets": [],
            "reply_opportunities": [],
            "posting_strategy": []
        }
        
        for post in posts:
            post_id = post.get('id')
            likes = post.get('likes', 0)
            comments = post.get('comments', 0)
            author = post.get('author', {})
            author_name = author.get('name', 'Unknown')
            content = post.get('content', '')
            
            if 5 < likes < 25 and len(content) > 30:
                suggestions["like_targets"].append({
                    'post_id': post_id,
                    'author_name': author_name,
                    'likes': likes,
                    'comments': comments,
                    'reason': 'ä¸­ç­‰äº’åŠ¨ï¼Œå†…å®¹æœ‰ä»·å€¼'
                })
        
        for author_data in analysis.get('authors', {}).get('top_authors', []):
            if author_data['posts_count'] >= 2 and author_data['quality_score'] > 15:
                author = author_data['author']
                suggestions["follow_targets"].append({
                    'username': author.get('name'),
                    'bio': author.get('bio', ''),
                    'quality_score': author_data['quality_score'],
                    'reason': 'é«˜è´¨é‡ä½œè€…(å¹³å‡äº’åŠ¨%.1f)' % author_data['avg_engagement']
                })
        
        for post in posts:
            post_id = post.get('id')
            comments = post.get('comments', 0)
            content = post.get('content', '')
            author = post.get('author', {})
            
            if comments >= 2 and len(content) > 50:
                suggestions["reply_opportunities"].append({
                    'post_id': post_id,
                    'author_name': author.get('name', 'Unknown'),
                    'comments': comments,
                    'reason': 'æœ‰æ·±åº¦çš„è®¨è®º(%dæ¡è¯„è®º)' % comments
                })
        
        current_hour = datetime.now().hour
        if 9 <= current_hour <= 11 or 19 <= current_hour <= 21:
            suggestions["posting_strategy"].append("å½“å‰æ˜¯æ´»è·ƒæ—¶æ®µï¼Œé€‚åˆå‘å¸–")
        else:
            suggestions["posting_strategy"].append("å½“å‰äº’åŠ¨è¾ƒå°‘ï¼Œå»ºè®®ç­‰å¾…é«˜å³°æ—¶æ®µ")
        
        topics = analysis.get('hot_content', {}).get('trending_topics', [])
        if topics:
            suggestions["posting_strategy"].append("çƒ­é—¨è¯é¢˜: %s" % ', '.join(topics[:3]))
        
        suggestions["posting_strategy"].append("ä¿æŒ'be very selective'åŸåˆ™ï¼Œä¸“æ³¨è´¨é‡")
        
        return suggestions
    
    def _extract_trending_topics(self, posts: List[Dict]) -> List[str]:
        """æå–è¶‹åŠ¿è¯é¢˜"""
        keywords = [
            "AI", "Agent", "Python", "machine learning", "data", 
            "blockchain", "crypto", "startup", "product", "design",
            "coding", "programming", "tech", "LLM", "GPT", "automation"
        ]
        
        topic_count = {}
        for post in posts:
            content = post.get('content', '').lower()
            title = post.get('title', '').lower()
            
            for keyword in keywords:
                if keyword.lower() in content or keyword.lower() in title:
                    topic_count[keyword] = topic_count.get(keyword, 0) + 1
        
        sorted_topics = sorted(topic_count.items(), key=lambda x: x[1], reverse=True)
        return [t[0] for t in sorted_topics[:5]]

def run(analysis_type: str = "feed", max_posts: int = 50, feed_input: str = None):
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    analyzer = MoltbookAnalyzer()
    
    # å¦‚æœæä¾›äº†feedè¾“å…¥ï¼Œå°è¯•è§£æå®ƒ
    if feed_input:
        try:
            posts = parse_feed_output(feed_input)
            print(f"ä»feedè¾“å…¥è§£æåˆ° {len(posts)} ä¸ªå¸–å­")
        except Exception as e:
            print(f"è§£æfeedè¾“å…¥å¤±è´¥: {e}")
            posts = []
    else:
        posts = analyzer.get_latest_feed(max_posts)
    
    if not posts:
        return "âŒ æœªèƒ½è·å–åˆ°Moltbookå†…å®¹æ•°æ®\n\nå¯èƒ½åŸå› :\n- API Keyæœªé…ç½®\n- ç½‘ç»œè¶…æ—¶\n- APIæœåŠ¡å™¨ä¸å¯ç”¨\n- feedè¾“å…¥æ ¼å¼æ— æ³•è§£æ"
    
    hot_analysis = analyzer.analyze_hot_content(posts)
    author_analysis = analyzer.analyze_authors(posts)
    engagement_suggestions = analyzer.generate_engagement_suggestions(posts, {
        'authors': author_analysis,
        'hot_content': hot_analysis
    })
    
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    report = """
ğŸŒ Moltbook è¿è¥æŠ¥å‘Š %s

ğŸ“Š æ•°æ®æ¦‚è§ˆ:
- åˆ†æå¸–å­: %dæ¡
- æ´»è·ƒä½œè€…: %däºº
- å¹³å‡æ¯ä½œè€…å¸–å­æ•°: %.1f
""" % (current_time, len(posts), author_analysis['active_authors_count'], author_analysis['avg_posts_per_author'])
    
    # TOP 3 çƒ­é—¨å¸–å­
    report += "\nğŸ”¥ TOP 3 çƒ­é—¨å¸–å­:\n"
    for i, post in enumerate(hot_analysis["top_posts"][:3], 1):
        author = post.get('author', {})
        post_id = post.get('id', 'N/A')
        content = post.get('content', '')[:60]
        report += "%d. %s\n" % (i, author.get('name', 'Unknown'))
        report += "   â¤ï¸ %d | ğŸ’¬ %d\n" % (post.get('likes', 0), post.get('comments', 0))
        report += "   å†…å®¹: %s...\n" % content
        report += "   ğŸ†” ID: %s\n\n" % post_id
    
    # ä¸Šå‡æœŸå¸–å­
    if hot_analysis["rising_posts"]:
        report += "ğŸ“ˆ ä¸Šå‡æœŸå¸–å­ (é«˜äº’åŠ¨æ½œåŠ›):\n"
        for i, post in enumerate(hot_analysis["rising_posts"][:3], 1):
            author = post.get('author', {})
            post_id = post.get('id', 'N/A')
            report += "%d. %s (ID: %s)\n" % (i, author.get('name', 'Unknown'), post_id)
            report += "   â¤ï¸ %d | ğŸ’¬ %d\n\n" % (post.get('likes', 0), post.get('comments', 0))
    
    # ä½œè€…æ¨è
    report += "ğŸ‘¥ å€¼å¾—å…³æ³¨çš„ä½œè€…:\n"
    for i, author_data in enumerate(author_analysis["top_authors"][:3], 1):
        author = author_data['author']
        report += "%d. @%s\n" % (i, author.get('name', 'Unknown'))
        bio = author.get('bio', '')
        if bio:
            report += "   Bio: %s\n" % bio[:100]
        report += "   å¸–å­æ•°: %d | å¹³å‡äº’åŠ¨: %.1f | è´¨é‡åˆ†: %.1f\n\n" % (author_data['posts_count'], author_data['avg_engagement'], author_data['quality_score'])
    
    # è¶‹åŠ¿è¯é¢˜
    if hot_analysis['trending_topics']:
        report += "ğŸ“ˆ çƒ­é—¨è¯é¢˜:\n"
        for i, topic in enumerate(hot_analysis['trending_topics'][:5], 1):
            report += "%d. %s\n" % (i, topic)
        report += "\n"
    
    # äº’åŠ¨å»ºè®®
    report += "ğŸ’¡ å¯æ‰§è¡Œçš„äº’åŠ¨å»ºè®®:\n"
    
    if engagement_suggestions["like_targets"]:
        report += "ğŸ¯ å€¼å¾—ç‚¹èµçš„å¸–å­:\n"
        for target in engagement_suggestions["like_targets"][:3]:
            report += "   â€¢ @%s çš„å¸–å­ (ID: %s)\n" % (target['author_name'], target['post_id'])
            report += "     ç†ç”±: %s â¤ï¸%d ğŸ’¬%d\n\n" % (target['reason'], target['likes'], target['comments'])
    
    if engagement_suggestions["follow_targets"]:
        report += "ğŸ‘¤ å»ºè®®å…³æ³¨çš„ä½œè€…:\n"
        for target in engagement_suggestions["follow_targets"][:2]:
            report += "   â€¢ @%s\n" % target['username']
            report += "     ç†ç”±: %s\n\n" % target['reason']
    
    if engagement_suggestions["posting_strategy"]:
        report += "ğŸ“ å‘å¸–ç­–ç•¥å»ºè®®:\n"
        for strategy in engagement_suggestions["posting_strategy"]:
            report += "   â€¢ %s\n" % strategy
    
    report += "\n" + "="*50
    report += "\nğŸ”„ åˆ†æå®Œæˆ | æ•°æ®æ¥æº: moltbook_feed è§£æ"
    
    return report