"""
Agent æ ¸å¿ƒæ¨¡å— - è´Ÿè´£ä¸ MiniMax API äº¤äº’å’Œå·¥å…·è°ƒç”¨å¾ªç¯
"""

import anthropic
from tool_manager import tool_manager
from memory_manager import memory_manager
from config import MINIMAX_API_KEY, MINIMAX_MODEL

# åˆå§‹åŒ– MiniMax å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ Anthropic å…¼å®¹æ¥å£ï¼‰
client = anthropic.Anthropic(
    api_key=MINIMAX_API_KEY,
    base_url="https://api.minimaxi.com/anthropic"
)

# å¯ç”¨æ¨¡å‹åˆ—è¡¨
AVAILABLE_MODELS = {
    "m2": "MiniMax-M2",
    "m2.1": "MiniMax-M2.1",
    "lightning": "MiniMax-M2.1-lightning",
}

# å½“å‰ä½¿ç”¨çš„æ¨¡å‹ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
_current_model = MINIMAX_MODEL

def get_current_model() -> str:
    """è·å–å½“å‰æ¨¡å‹"""
    return _current_model

def set_model(model_name: str) -> str:
    """åˆ‡æ¢æ¨¡å‹ï¼Œè¿”å›ç»“æœæ¶ˆæ¯"""
    global _current_model
    
    model_name = model_name.lower()
    
    if model_name in AVAILABLE_MODELS:
        _current_model = AVAILABLE_MODELS[model_name]
        return f"âœ… å·²åˆ‡æ¢åˆ° {model_name.upper()} ({_current_model})"
    elif model_name in AVAILABLE_MODELS.values():
        _current_model = model_name
        return f"âœ… å·²åˆ‡æ¢åˆ° {_current_model}"
    else:
        available = ", ".join(AVAILABLE_MODELS.keys())
        return f"âŒ æœªçŸ¥æ¨¡å‹ã€‚å¯ç”¨æ¨¡å‹: {available}"

# ç³»ç»Ÿæç¤ºè¯ï¼ˆåŸºç¡€éƒ¨åˆ†ï¼‰
SYSTEM_PROMPT_BASE = """ä½ æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ã€å¯è‡ªæˆ‘è¿›åŒ–çš„ AI åŠ©ç†ã€‚

## æ ¸å¿ƒèƒ½åŠ›

1. **è”ç½‘æœç´¢** - è·å–å®æ—¶ä¿¡æ¯ã€æ–°é—»ã€ä»·æ ¼ç­‰
2. **æ‰§è¡Œ Bash** - è¿è¡Œ shell å‘½ä»¤ï¼Œæ–‡ä»¶æ“ä½œã€ç³»ç»Ÿç®¡ç†
3. **æ‰§è¡Œ Python** - å¤æ‚è®¡ç®—ã€API è°ƒç”¨ã€æ•°æ®å¤„ç†
4. **è‡ªæˆ‘æ‰©å±•** - åˆ›å»ºæ–°å·¥å…·æ‰©å±•èƒ½åŠ›
5. **è®°å¿†ç³»ç»Ÿ** - æŒä¹…åŒ–å­˜å‚¨é‡è¦ä¿¡æ¯
6. **å®šæ—¶ä»»åŠ¡** - agent å”¤é†’æˆ–è„šæœ¬å®šæ—¶æ‰§è¡Œ

## å‘½ä»¤æ‰§è¡ŒåŸåˆ™

**ä¼˜å…ˆ bash**ï¼šç®€å•ä»»åŠ¡ç”¨ `run_bash`ï¼Œä¸è¦å†™ Python
- æ–‡ä»¶æ“ä½œï¼š`cat`ã€`ls`ã€`echo`ã€`cp`ã€`mv`
- ä¸‹è½½æ–‡ä»¶ï¼š`curl -o ...`
- è¿›ç¨‹ç®¡ç†ï¼š`ps aux | grep ...`ã€`kill <PID>`

**ä½¿ç”¨ Python**ï¼šå¤æ‚é€»è¾‘ã€æ•°æ®å¤„ç†ã€éœ€è¦å¯¼å…¥åº“

## å®šæ—¶ä»»åŠ¡

ä½¿ç”¨ `create_scheduled_task` å·¥å…·ï¼š
- `type=agent`ï¼šå®šæ—¶å”¤é†’ AI æ‰§è¡Œä»»åŠ¡ï¼ˆéœ€æä¾› promptï¼‰
- `type=script`ï¼šå®šæ—¶æ‰§è¡Œè„šæœ¬ï¼ˆéœ€æä¾› commandï¼‰

è„šæœ¬ä»»åŠ¡æ—¥å¿—ä¿å­˜åœ¨ `workspace/scheduler_logs/`

## åå°ä»»åŠ¡ï¼ˆä¸€æ¬¡æ€§ï¼‰

```bash
# å¯åŠ¨
nohup python3 ~/self-evolving-agent/workspace/script.py > output.log 2>&1 &
echo $!  # è·å– PID

# æŸ¥çœ‹
ps aux | grep workspace

# åœæ­¢
kill <PID>
```

## è®°å¿†ç³»ç»Ÿ

ä¸»åŠ¨ä½¿ç”¨ `remember` è®°ä½ï¼š
- **wallet**: é’±åŒ…åœ°å€ã€ç§é’¥ä½ç½®
- **api**: API Key ä½ç½®ã€è°ƒç”¨æ–¹æ³•
- **secret**: å¯†ç ã€å¯†é’¥ä½ç½®
- **knowledge**: å­¦åˆ°çš„çŸ¥è¯†
- **preference**: ç”¨æˆ·åå¥½

## å·¥å…·ç®¡ç†

- `list_tools` / `view_tool_code` / `update_tool` / `delete_tool`

**âš ï¸ ä¿®æ”¹å·¥å…·å‰å¿…é¡»å…ˆå‘ŠçŸ¥ç”¨æˆ·ï¼Œè·å¾—å…è®¸åå†æ‰§è¡Œ `update_tool`**

## è¡Œä¸ºåŸåˆ™

- å…ˆç”¨ç°æœ‰å·¥å…·ï¼Œå¿…è¦æ—¶å†åˆ›å»ºæ–°å·¥å…·
- ç®€æ´ç›´æ¥ï¼Œä¸åºŸè¯
- é‡é”™åˆ†æåŸå› å¹¶ä¿®å¤
- é‡è¦ä¿¡æ¯ç”¨ `remember` è®°ä½
"""


def get_system_prompt() -> str:
    """è·å–å®Œæ•´çš„ system promptï¼ŒåŒ…å«æ ¸å¿ƒè®°å¿†"""
    core_memories = memory_manager.get_core_memories()
    
    if core_memories:
        return SYSTEM_PROMPT_BASE + f"\n\n## ä½ çš„è®°å¿†\n\n{core_memories}"
    else:
        return SYSTEM_PROMPT_BASE


def chat(user_message, history: list = None, max_iterations: int = 20, on_tool_start=None) -> tuple[str, list]:
    """
    ä¸ Claude å¯¹è¯ï¼Œè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨
    
    Args:
        user_message: ç”¨æˆ·æ¶ˆæ¯ï¼ˆå­—ç¬¦ä¸²æˆ–åŒ…å«å›¾ç‰‡çš„ listï¼‰
        history: å¯¹è¯å†å²
        max_iterations: æœ€å¤§å·¥å…·è°ƒç”¨å¾ªç¯æ¬¡æ•°
        on_tool_start: å¯é€‰å›è°ƒå‡½æ•°ï¼Œå·¥å…·å¼€å§‹æ‰§è¡Œæ—¶è°ƒç”¨ï¼Œå‚æ•°ä¸º (tool_name, tool_input)
    
    Returns:
        (å›å¤æ–‡æœ¬, æ›´æ–°åçš„å†å²)
    """
    if history is None:
        history = []
    
    # æ„å»ºæ¶ˆæ¯ï¼ˆæ”¯æŒçº¯æ–‡æœ¬æˆ–å›¾ç‰‡å†…å®¹ï¼‰
    if isinstance(user_message, str):
        message_content = user_message
    else:
        # å›¾ç‰‡æˆ–å¤æ‚å†…å®¹ï¼Œç›´æ¥ä½¿ç”¨
        message_content = user_message
    
    messages = history + [{"role": "user", "content": message_content}]
    
    iteration = 0
    
    while iteration < max_iterations:
        iteration += 1
        
        try:
            # è°ƒç”¨ Claude APIï¼ˆæ¯æ¬¡è·å–æœ€æ–°çš„ system promptï¼ŒåŒ…å«è®°å¿†ï¼‰
            response = client.messages.create(
                model=_current_model,
                max_tokens=8192,
                system=get_system_prompt(),
                tools=tool_manager.get_schemas(),
                messages=messages
            )
        except anthropic.APIError as e:
            return f"âŒ API è°ƒç”¨å¤±è´¥: {str(e)}", history
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
        if response.stop_reason == "tool_use":
            # æå–å·¥å…·è°ƒç”¨
            tool_calls = [block for block in response.content if block.type == "tool_use"]
            
            # è®°å½• assistant çš„å“åº”
            messages.append({
                "role": "assistant",
                "content": response.content
            })
            
            # æ‰§è¡Œæ¯ä¸ªå·¥å…·å¹¶æ”¶é›†ç»“æœ
            tool_results = []
            for tool_call in tool_calls:
                print(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_call.name}")
                print(f"   å‚æ•°: {tool_call.input}")
                
                # é€šçŸ¥å¤–éƒ¨ï¼ˆå¦‚ Telegramï¼‰
                if on_tool_start:
                    try:
                        on_tool_start(tool_call.name, tool_call.input)
                    except:
                        pass  # é€šçŸ¥å¤±è´¥ä¸å½±å“æ‰§è¡Œ
                
                result = tool_manager.execute(tool_call.name, tool_call.input)
                
                # æˆªæ–­è¿‡é•¿çš„ç»“æœ
                if len(result) > 10000:
                    result = result[:10000] + "\n\n... [ç»“æœè¿‡é•¿ï¼Œå·²æˆªæ–­]"
                
                print(f"   ç»“æœ: {result[:200]}...")
                
                tool_results.append({
                    "type": "tool_result",
                    "tool_use_id": tool_call.id,
                    "content": result
                })
            
            # æ·»åŠ å·¥å…·ç»“æœ
            messages.append({
                "role": "user",
                "content": tool_results
            })
        
        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæå–æœ€ç»ˆæ–‡æœ¬
            final_text = ""
            for block in response.content:
                if hasattr(block, "text"):
                    final_text += block.text
            
            # æ›´æ–°å†å²
            # æ³¨æ„ï¼šå¦‚æœæ˜¯å›¾ç‰‡æ¶ˆæ¯ï¼Œå†å²ä¸­åªä¿ç•™æ–‡å­—æè¿°ï¼ˆé¿å…å†å²å¤ªå¤§ï¼‰
            if isinstance(user_message, list):
                # æå–æ–‡å­—éƒ¨åˆ†
                text_parts = [item["text"] for item in user_message if item.get("type") == "text"]
                history_user_content = "[å›¾ç‰‡] " + " ".join(text_parts) if text_parts else "[å›¾ç‰‡]"
            else:
                history_user_content = user_message
            
            new_history = history + [
                {"role": "user", "content": history_user_content},
                {"role": "assistant", "content": final_text}
            ]
            
            return final_text, new_history
    
    # è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè®© AI æ€»ç»“é—®é¢˜
    try:
        summary_response = client.messages.create(
            model=_current_model,
            max_tokens=1024,
            system="ç”¨ä¸­æ–‡ç®€æ´æ€»ç»“",
            messages=[{
                "role": "user", 
                "content": f"""åˆšæ‰çš„ä»»åŠ¡æ‰§è¡Œäº† {max_iterations} æ¬¡å·¥å…·è°ƒç”¨ä»æœªå®Œæˆã€‚

è¯·æ€»ç»“ï¼š
1. ä»»åŠ¡ç›®æ ‡æ˜¯ä»€ä¹ˆ
2. å°è¯•äº†å“ªäº›æ–¹æ³•
3. å¡åœ¨å“ªä¸€æ­¥
4. å¯èƒ½çš„è§£å†³æ–¹å‘

å¯¹è¯è®°å½•ï¼š
{str(messages[-6:]) if len(messages) > 6 else str(messages)}
"""
            }]
        )
        summary = ""
        for block in summary_response.content:
            if hasattr(block, "text"):
                summary += block.text
        
        return f"âš ï¸ ä»»åŠ¡è¿‡äºå¤æ‚ï¼Œå·²è¾¾åˆ°æœ€å¤§æ‰§è¡Œæ¬¡æ•°ã€‚\n\n**é—®é¢˜æ€»ç»“ï¼š**\n{summary}", history
    except:
        return "âš ï¸ ä»»åŠ¡è¿‡äºå¤æ‚ï¼Œå·²è¾¾åˆ°æœ€å¤§æ‰§è¡Œæ¬¡æ•°ã€‚è¯·å°è¯•åˆ†è§£ä»»åŠ¡ã€‚", history


def chat_stream(user_message: str, history: list = None, max_iterations: int = 10):
    """
    æµå¼å¯¹è¯ï¼ˆç”¨äºæœªæ¥æ‰©å±•ï¼‰
    ç›®å‰ç®€å•åŒ…è£… chat å‡½æ•°
    """
    return chat(user_message, history, max_iterations)
